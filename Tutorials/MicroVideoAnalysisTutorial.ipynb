{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a20f45e",
   "metadata": {},
   "source": [
    "# Analysing TEM videos with SimpliPyTEM\n",
    "\n",
    "This project was born out of a need for rapid, easily accesible and effective analysis methods for analysis of in situ TEM videos. Python is a very powerful language for this type of analysis based on the wide accessibility of different packages to perform a range of functions on the image. However, for many cases this makes the barriers for entry much harder and the location of relevant functions difficult to find. Here I have collated a number of methods into a single python object to make it easier to deal with electron microscopy videos, particularly those collected with gatan software. \n",
    "\n",
    "Before working through this tutorial, I recommend looking at the micrograph tutorial, as the concepts are the same and explained in more detail there, this is mainly looking to scale image based tutorials to videos, and most of the functions involved do exactly that. \n",
    "\n",
    "This method is specifically designed for use of videos taken as dm4 movies, as produced from gatan direct electron detectors (eg. our k2 camera). However, once the image and pixelsize are loaded, all the functions should work just as well for other formats, To see how I have used it for a screen recording, see the accompanying tutorial: '    '*** \n",
    "\n",
    "Again this mainly works out of a single class, this time named 'MicroVideo'. I'll start in a similar way to before, however proceed quicker than in the previous tutorial. \n",
    "\n",
    "## Import dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a60d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimpliPyTEM.MicroVideo_class import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37d34d0",
   "metadata": {},
   "source": [
    "## Initialise MicroVideo object and open MicroVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a11fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = MicroVideo()\n",
    "print([x for x in os.listdir('.') if 'dm4' in x])\n",
    "video.open_dm('gold_growth_video_holder_test_070921.dm4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbf1b55",
   "metadata": {},
   "source": [
    "Like the Micrograph object, the MicroVideo object contains lot of useful data and useful methods, as well as the video itself. To access the video frames run: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20300a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video.frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c376fc06",
   "metadata": {},
   "source": [
    "Again, this is no use, these need to be plotted to see anything useful from them, however we can see some information about the size and length of the video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed96e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video.frames.shape)\n",
    "# or simply:\n",
    "print(video.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3defbd67",
   "metadata": {},
   "source": [
    "So this is a 13-frame video, with a size of 3834 x 3702 (numpy arrays have x and y opposite from normal image programs), lets have a look at how the first frame looks: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fbb167",
   "metadata": {},
   "source": [
    "We can also use other video formats e.g. avi or mp4, or load from an array, here the pixelsize and pixelunit are manually inputed: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee348002",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x for x in os.listdir('.') if x[-3:]=='avi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c545c92",
   "metadata": {},
   "source": [
    "## Loading videos from Avi/Mp4\n",
    "\n",
    "Videos can be easily loaded from avi's or Mp4's, however these dont have a pixelsize or pixelunit by default, and also miss the metadata. This is simply achieved as follows:\n",
    "\n",
    "Note that the files opened here are created at the end of the notebook and are not shipped with the tutorial, so either change the filename (Output_video.___ or do the rest of the tutorial before trying this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b52e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "avi_vid = MicroVideo()\n",
    "avi_vid.open_video('Output_video.avi', pixelsize=0.1, pixelunit='nm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_vid = MicroVideo()\n",
    "mp4_vid.open_video('Output_video.mp4', pixelsize=0.1, pixelunit='nm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfe48d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avi_vid.pixelSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e2752b",
   "metadata": {},
   "source": [
    "\n",
    "## Showing video stills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a8f2e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "video.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d795b",
   "metadata": {},
   "source": [
    "Well thats not very revealing! \n",
    "Clearly each frame is quite low contrast, lets see what the histogram looks like.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8435bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.plot_histogram(sidebyside=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ed5df0",
   "metadata": {},
   "source": [
    "So we dont have much signal, but we an also see that the maximum pix value is 12 (the x axis maximum) despite the fact that there are very few pixels with counts above 5. \n",
    "\n",
    "Lets see if we can display it better using the matplotlib library using plt.imshow() whilst adding limits into it.\n",
    "\n",
    "We can do this by adding the vmax and vmin arguments to video.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e1af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.imshow(vmax=4, vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40c21f2",
   "metadata": {},
   "source": [
    "Well thats still quite noisy, but we can at least see the particles a bit better! This is a low dose video with a relatively fast frame rate (we'll see how fast when discussing the metadata later)!\n",
    "\n",
    "Lets trying to see what an average (or technically a sum) of this video looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216242d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.imshow(average=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a336a",
   "metadata": {},
   "source": [
    "Much better! the particles have much clearer outlines, still not plotting very well though, lets try plotting with a vmax set again. Here rather than using a built-in function, I am using numpy sum all the video frame into a single array - this works on the time/Z axis (axis 0). \n",
    "\n",
    "Remember though: as we are summing the frames, the vmax needs to increase as well! We can replot the histogram with the average to see what would be suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b93c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.plot_histogram(imAverage=True, histAverage=True,sidebyside=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411629ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.imshow(average=True, vmax=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb8d90c",
   "metadata": {},
   "source": [
    "Well thats a bit clearer, but I'm sure we can do better! I'll come back to that later on. \n",
    "\n",
    "\n",
    "Sometimes, I have taken a video, however I want to treat it like a single image. In these instances, the to_micrograph() function can be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d91eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = video.toMicrograph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8fc7d",
   "metadata": {},
   "source": [
    "Now we have a micrograph object: 'im', we can see the type of this as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cfdfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbea43d",
   "metadata": {},
   "source": [
    "Now im can be used as shown in the micrograph tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8db929e",
   "metadata": {},
   "source": [
    "## Showing video\n",
    "\n",
    "we can video in a jupyter notebook as follows. This method is slow but will show you the animated video, use the 'reduce_size' function to reduce the size of the video shown.\n",
    "\n",
    "Furthermore the vmax and vmin options shown above work in the same way here. I recommend finding a good vmax/vmin using the imshow() command before making the video, as this step can take a long time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00943fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.show_video(reduce_size=5, vmax=5, vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb594ff",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "So like with the micrographs, metadata from dm files is automatically loaded in and can be easily accessed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78283386",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video.pixelSize)\n",
    "print(video.pixelUnit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5761a55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps, time = video.get_exposure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d5ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "date, time = video.get_date_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413290e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video.fps)\n",
    "print(video.AqDate)\n",
    "print(video.AqTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bda6548",
   "metadata": {},
   "source": [
    "If you have other video formats which include metadata and you would like this built in, feel free to request it and I will try to add it to the package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5de9da",
   "metadata": {},
   "source": [
    "## Video transformations\n",
    "\n",
    "Here are the useful bits.\n",
    "\n",
    "### Averaging the video\n",
    "\n",
    "Often in situ EM videos have very little signal in each individual frames, and so we need to average multiple frames together. There are two built in functions for this: Average_frames and Running_average.\n",
    "\n",
    "These functions both return a new object with the frames averaged together:\n",
    "   \n",
    "    - Average_frames simply splits the video into groups of n frames and sums these. \n",
    "    \n",
    "    - Running_average performs a 'sliding window' averaging preceedure, frames are still split into groups of n frames, however in this case these overlap with only a single frame offset. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac262d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Simple_average = video.Average_frames(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ef5bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Simple_average.imshow(vmax=8, vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe5ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Running_average = video.Running_average(3)\n",
    "Running_average.imshow(vmax=8, vmin=0, framenumber=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80806cd8",
   "metadata": {},
   "source": [
    "These look the same right? That is because they are. The first frame of these both will be the same, the difference is the number of frames (and therefore the time resolution available):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a2b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The original video has {} frames'.format(len(video)))\n",
    "print('The simple average has {} frames'.format(len(Simple_average)))\n",
    "print('The running average has {} frames'.format(len(Running_average)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea0e87b",
   "metadata": {},
   "source": [
    "The advantage of running averging is that it retains some of the time resolution that is lost in averaging, however it is the changes between frames are significantly reduced by this averaging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c550b",
   "metadata": {},
   "source": [
    "Here I am going to reset the variables to reduce memory space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21610935",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset_selective -f Simple_average\n",
    "%reset_selective -f Running_average\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab3b1c6",
   "metadata": {},
   "source": [
    "## xy bin video \n",
    "\n",
    "Reducing size on the XY axis can be very useful for processing times as it greatly reduces the size of the video and therefore the number of pixels, and the data included. It will also lead to increased contrast.\n",
    "\n",
    "This is done very simply: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92092b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_binned = video.bin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be2b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video_binned.frames.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee3eec",
   "metadata": {},
   "source": [
    "From here on out I will use the binned video to speed up the processing times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7377785",
   "metadata": {},
   "outputs": [],
   "source": [
    "video=video.bin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6122e554",
   "metadata": {},
   "source": [
    "### Convert to 8-bit\n",
    "\n",
    "This scales the video between 0 and 255, more details are given in the micrograph tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5560711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original histogram\n",
    "\n",
    "video.plot_histogram(sidebyside=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "video8bit = video.convert_to_8bit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e8db40",
   "metadata": {},
   "source": [
    "Lets check if its different! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3faed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "video8bit.plot_histogram(sidebyside=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c25b4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f762bda8",
   "metadata": {},
   "source": [
    "So we have scaled the video between 0 and 255, however we can still see the histogram is skewed to the right, with almost no pixels having a light value, now we can see this better by adding vmax/vmin into the image, however we can also use the methods below to improve this. \n",
    "\n",
    "\n",
    "## Contrast enhancement \n",
    "\n",
    "The MicroVideo class has the same contrast enhancement methods as the Micrograph class. \n",
    "\n",
    "Clip contrast is my favourite method - this simply adjusts the blackpoint and whitepoint of the image, the maximum and minimum pixel values in the image,  and scales the pixel values to these new points. \n",
    "\n",
    "The maximum and minimum value can be given using the maxvalue and minvalue options, however this can also be automated using the (default) saturation option. This decides what percentage of pixels are white/black, such that saturation = 0.5 means that 0.5% of pixels in the video are white and 0.5% of pixels are black. One of the minimum/maximum can also be used and the other will work with the saturation method. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "video8bit_clipped = video8bit.clip_contrast(saturation=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "video8bit_clipped.plot_histogram(sidebyside=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169dffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "video8bit_clipped = video8bit.clip_contrast(maxvalue = 80, minvalue =0 )\n",
    "video8bit_clipped.plot_histogram(sidebyside=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3412a502",
   "metadata": {},
   "source": [
    "Other methods to enhance the contrast are included, these are 'enhance_contrast' using OpenCV's built in methods allowing for alpha (contrast), beta (brightness) and gamma (non-linear brightness) control. Histogram equalisation (ensuring a good spread of pixel values, or a flat histogram) is also included. \n",
    "\n",
    "These methods are discussed in more detail in the micrograph analysis tutorial, and work in the same way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c416d583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dda4cc89",
   "metadata": {},
   "source": [
    "## Video filters\n",
    "\n",
    "A number of video filters are available, as with the micrograph class: \n",
    "\n",
    " - Median filter: performs a median filter with kernal size defined in the call (default is 3)\n",
    " \n",
    " - Gaussian filter: performs a Gaussian filter with kernal size defined in the call (default is 3)\n",
    " \n",
    " - Weiner filter: performs a Weiner filter with kernal size defined in the call (default is 5)\n",
    " \n",
    " - Low pass filter: performs a 2D fourier transform of the image and removes the  \n",
    " \n",
    " - Non-local means filter: this compares similar regions of the image and denoises by averaging across them. This is performed by openCV, and more info can be found here: https://docs.opencv.org/3.4/d5/d69/tutorial_py_non_local_means.html\n",
    "\n",
    "\n",
    "The syntax for these are all the same:\n",
    "    \n",
    "   > filtered_video_object = video.*****_filter(strength)\n",
    "    \n",
    "where \\**** is one of the following: \n",
    "> median \n",
    ">\n",
    "> gaussian\n",
    ">\n",
    "> weiner\n",
    ">\n",
    "> low_pass\n",
    ">\n",
    "> NLM\n",
    "\n",
    "The 'Strength' value is more vairable, however all except the low pass filter have default values between 3 and 11, and require odd values (because they require a n\\*n kernal with a single middle value. \n",
    "\n",
    "\n",
    "For more details on each function look at the micrograph analysis tutorial or  run\n",
    "\n",
    "   > help(video.****_filter)\n",
    "   \n",
    "These are all used to reduce the noise in the image in different ways, and can be effective in difference circumstances, I recommend trying out all of them, in particular the median, gaussian and low pass filters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a9cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_gaussian = video8bit.gaussian_filter(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd3b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_gaussian.plot_histogram(sidebyside=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18cf91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_gaussian_clipped = video_gaussian.clip_contrast()\n",
    "video_gaussian_clipped.plot_histogram(sidebyside=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7738e98d",
   "metadata": {},
   "source": [
    "I like how this looks, so I will proceed with this video and remove the remaining videos to reduce memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f96b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = video_gaussian_clipped\n",
    "\n",
    "%reset_selective -f video_gaussian\n",
    "%reset_selective -f video8bit\n",
    "%reset_selective -f video_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45bcaab",
   "metadata": {},
   "source": [
    "## Add scalebar\n",
    "This is super simple - just run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91330662",
   "metadata": {},
   "outputs": [],
   "source": [
    "videoSB = video.make_scalebar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afc5eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "videoSB.plot_histogram()\n",
    "videoSB.imshow(average=True, vmax=50,vmin=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d049047",
   "metadata": {},
   "source": [
    "## Saving data \n",
    "\n",
    "We have multiple choice when saving the data, we can save a single frame, an average frame,  a sequence of images, a tif 'stack' (all frames in one file) , an .avi video and an mp4 video. These have simple syntax: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a740c50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video.write_image('Video_averaged',average=True)\n",
    "video.write_image('First_frame', average=False, framenumber=0)\n",
    "video.write_image('Last_frame', average=False,framenumber=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a6e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.save_tif_sequence(outdir='Frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.save_tif_stack(outdir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e0d032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video.write_video('Output_video.mp4')\n",
    "video.write_video('Output_video.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812f1258",
   "metadata": {},
   "source": [
    "# Advanced functions\n",
    "\n",
    "While the above functions will be good enough for many examples, there are some more specific functions, I may add more functions here from time to time. \n",
    "\n",
    "## Video normalisation \n",
    "\n",
    "Often the contrast in videos change significantly over frames, which can be distracting. Contrast can be normalised across the frames using either mean or median normalisation - these ensure the mean or median values of each frames are equal, so far these have appeared to give similar results so try either and if that doesnt sort your needs, try the other\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e012a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_video = video.Normalise_video(normtype='mean')\n",
    "normalised_video = video.Normalise_video(normtype='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811c5438",
   "metadata": {},
   "source": [
    "## Local normalisation \n",
    "\n",
    "Soon to appear! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
